[
["index.html", "MLE of Location Parameter of a Cauchy Distribution by Using Different Algorithms 1 Proofs and Loglikelihood Function Plot against \\(\\theta\\) 1.1 Proofs 1.2 Loglikelihood Function Plot against \\(\\theta\\)", " MLE of Location Parameter of a Cauchy Distribution by Using Different Algorithms HW 3 of STAT 5361 Statistical Computing Biju Wang1 09/17/2018 1 Proofs and Loglikelihood Function Plot against \\(\\theta\\) 1.1 Proofs The likelihood function is \\[L(\\theta)=\\prod^{n}_{i=1}\\frac{1}{\\pi[1+(X_{i}-\\theta)^{2}]}\\] Hence, the log likelihood fucntion is \\[\\begin{equation} l(\\theta)=\\log L(\\theta)=\\log \\prod^{n}_{i=1}\\frac{1}{\\pi[1+(X_{i}-\\theta)^{2}]}=-n\\log\\pi-\\sum^{n}_{i=1}\\log[1+(\\theta-X_{i})^{2}] \\end{equation}\\] Further \\[\\begin{equation} l&#39;(\\theta)=-\\sum^{n}_{i=1}\\frac{d}{d\\theta}\\log[1+(\\theta-X_{i})^{2}]=-2\\sum^{n}_{i=1}\\frac{\\theta-X_{i}}{1+(\\theta-X_{i})^{2}} \\end{equation}\\] Compute the second derivative according to \\(l&#39;(\\theta)\\) \\[\\begin{equation} l&#39;&#39;(\\theta)=-2\\sum^{n}_{i=1}\\frac{d}{d\\theta}\\frac{\\theta-X_{i}}{1+(\\theta-X_{i})^{2}}=-2\\sum^{n}_{i=1}\\frac{1-(\\theta-X_{i})^{2}}{[1+(\\theta-X_{i})^{2}]^{2}} \\end{equation}\\] Therefore, the Fisher information is \\[\\begin{equation} \\begin{split} I_{n}(\\theta) &amp;=-E_{X}[l&#39;&#39;(\\theta)]\\\\ &amp;=2nE_{X}\\left[\\frac{1-(\\theta-X)^{2}}{[1+(\\theta-X)^{2}]^{2}}\\right]\\\\ &amp;=2n\\int^{\\infty}_{-\\infty}\\frac{1-(x-\\theta)^{2}}{[1+(x-\\theta)^{2}]^{2}}\\frac{1}{\\pi[1+(x-\\theta)^{2}]}dx\\\\ &amp;=\\frac{2n}{\\pi}\\int^{\\infty}_{-\\infty}\\frac{1-x^{2}}{(1+x^{2})^{2}}\\frac{1}{1+x^{2}}dx=\\frac{2n}{\\pi}\\int^{\\infty}_{-\\infty}\\left(\\frac{x}{1+x^{2}}\\right)&#39;\\frac{1}{1+x^{2}}dx=\\frac{2n}{\\pi}\\left[\\left.\\frac{x}{(1+x^{2})^{2}}\\right|^{\\infty}_{-\\infty}+\\int^{\\infty}_{-\\infty}\\frac{2x^{2}}{(1+x^{2})^{3}}\\right]\\\\ &amp;=\\frac{4n}{\\pi}\\int^{\\infty}_{-\\infty}\\frac{x^{2}}{(1+x^{2})^{3}}dx=\\frac{4n}{\\pi}\\int^{\\frac{\\pi}{2}}_{-\\frac{\\pi}{2}}\\frac{\\tan^{2}\\alpha}{(1+\\tan^{2}\\alpha)^{3}}\\sec^{2}\\alpha d\\alpha=\\frac{4n}{\\pi}\\int^{\\frac{\\pi}{2}}_{-\\frac{\\pi}{2}}\\frac{1-\\cos 4\\alpha}{8}d\\alpha=\\frac{4n}{\\pi}\\cdot\\frac{\\pi}{8}\\\\ &amp;=\\frac{n}{2} \\end{split} \\end{equation}\\] 1.2 Loglikelihood Function Plot against \\(\\theta\\) The following plot is the curve of log likelihood function set.seed(20180909) sample &lt;- rcauchy(10, 5) log_sum &lt;- function(x, sample){ log_sum &lt;- 0 for (i in 1:length(sample)) { log_sum &lt;- log_sum -log(pi) - log(1 + (x - sample[i])^2) } log_sum } library(&quot;ggplot2&quot;) ggplot(data.frame(x = c(0, 10)), aes(x = x)) + stat_function(fun = function(x) log_sum(x, sample)) + labs(x = expression(&quot;Values of&quot;~theta), y = expression(&quot;Log Likelihood Function&quot;~l(theta))) + theme(plot.title = element_text(hjust = 0.5)) + ggtitle(expression(&quot;Log Likelihood Function vs.&quot;~theta)) Figure 1.1: Log Likelihood Function vs. \\(\\theta\\) bijuwang@uconn.eduâ†© "],
["newton-raphson-method.html", "2 Newton-Raphson Method", " 2 Newton-Raphson Method set.seed(20180909) sample &lt;- rcauchy(10, 5) log_sum &lt;- function(x){ log_sum &lt;- 0 for (i in 1:length(sample)) { log_sum &lt;- log_sum -log(pi) - log(1 + (x - sample[i])^2) } log_sum } dev1_log_sum &lt;- function(x){ dev1_log_sum &lt;- 0 for (i in 1:length(sample)) { dev1_log_sum &lt;- dev1_log_sum - 2 * (x - sample[i])/(1 + (x - sample[i])^2) } dev1_log_sum } dev2_log_sum &lt;- function(x){ dev2_log_sum &lt;- 0 for (i in 1:length(sample)) { dev2_log_sum &lt;- dev2_log_sum - 2 * (1 - (x - sample[i])^2)/(1 + (x - sample[i])^2)^2 } dev2_log_sum } newton.raphson &lt;- function(init, fun, fun.dev, maxiter = 100, tol = .Machine$double.eps^0.2){ x &lt;- init for (i in 1:maxiter) { x1 &lt;- x -fun(x)/fun.dev(x) if(abs(x1 - x) &lt; tol) break x &lt;- x1 } if(i == maxiter) message(&quot;Reached the maximum iteration!&quot;) return(data.frame(root = x1, iter = i)) } init &lt;- seq(-10, 20, by = 0.5) res &lt;- data.frame(init = init, root = rep(NA, length(init))) for (i in 1:length(init)) { res$root[i] &lt;- newton.raphson(init[i], dev1_log_sum, dev2_log_sum)$root } res_trans &lt;- t(as.matrix(round(res, 2))) rownames(res_trans) &lt;- c(&quot;Initial Values&quot;, &quot;Roots&quot;) library(&quot;pander&quot;) library(&quot;ggplot2&quot;) pander(res_trans, split.table = 100, style = &#39;rmarkdown&#39;) Table continues below Initial Values -10 -9.5 -9 -8.5 -8 Roots -2.162e+31 -2.097e+31 -2.031e+31 -1.965e+31 -1.9e+31 Table continues below Initial Values -7.5 -7 -6.5 -6 -5.5 Roots -1.834e+31 -1.768e+31 -1.701e+31 -1.635e+31 -1.569e+31 Table continues below Initial Values -5 -4.5 -4 -3.5 -3 Roots -1.502e+31 -1.436e+31 -1.369e+31 -1.302e+31 -1.235e+31 Table continues below Initial Values -2.5 -2 -1.5 -1 -0.5 Roots -1.167e+31 -1.1e+31 -1.032e+31 -9.648e+30 -8.97e+30 Table continues below Initial Values 0 0.5 1 1.5 2 Roots -8.295e+30 -7.623e+30 -6.962e+30 -6.327e+30 -5.76e+30 Table continues below Initial Values 2.5 3 3.5 4 4.5 5 5.5 Roots -5.397e+30 -5.999e+30 7.515e+31 21.08 19.38 5.69 5.69 Table continues below Initial Values 6 6.5 7 7.5 8 8.5 9 Roots 5.69 5.69 1.608e+31 -4.779e+30 20.56 19.38 5.69 Table continues below Initial Values 9.5 10 10.5 11 11.5 12 12.5 Roots -4.38e+30 19.38 5.69 3.72e+30 2.215e+31 21.08 21.08 Table continues below Initial Values 13 13.5 14 14.5 15 15.5 16 16.5 Roots 21.08 19.38 19.38 19.38 20.56 21.08 21.08 20.56 Initial Values 17 17.5 18 18.5 19 19.5 20 Roots 20.56 20.56 -1.413e+30 21.08 21.08 21.08 21.08 ggplot(res, aes(x = init, y = root)) + geom_point() + scale_x_continuous(breaks = round(seq(min(res$init), max(res$init), by = 1),1)) + labs(x = &quot;Initial Values&quot;, y = &quot;Roots from Newton-Raphson&quot;) + theme(plot.title = element_text(hjust = 0.5)) + ggtitle(&quot;Scatter Plot of Roots vs. Initial Values&quot;) Figure 2.1: Scatter Plot of Roots vs. Initial Values From the above table and figure we can see, when the initial values is not less than \\(5\\) and around \\(5\\), the outcomes are quite close to the true value \\(5\\). For instance, from the table when the initial values are \\(5, 5,5, 6, 6.5\\), the roots are \\(5.69, 5.69, 5.69, 5.69\\). While for other initial values, the roots are quite unstable, for some the roots are very large and for others the roots only have magnitude of \\(10\\). "],
["fixed-point-iterations.html", "3 Fixed-Point Iterations", " 3 Fixed-Point Iterations "],
["fisher-scoring-method-and-newton-raphson-method.html", "4 Fisher Scoring Method and Newton-Raphson Method", " 4 Fisher Scoring Method and Newton-Raphson Method "],
["comments.html", "5 Comments", " 5 Comments "],
["references.html", "References", " References "]
]
